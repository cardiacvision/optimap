{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "source": [
    "```{currentmodule} optimap\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "from optimap.utils import jupyter_render_animation as render"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "source": [
    "```{tip}\n",
    "Download this tutorial as a {download}`Jupyter notebook <converted/activation.ipynb>`, or a {download}`python script <converted/activation.py>` with code cells. We highly recommend using [Visual Studio Code](#vscode) to execute this tutorial.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 6: Activation Maps\n",
    "\n",
    "This tutorial demonstrates how to compute local activation times and activation maps from cardiac optical mapping data using ``optimap``. Local activation times (often referred to as LATs) are times at which the tissue becomes electrically activated. \n",
    "\n",
    "Computing local activation times corresponds to determining when the optical signal in a given pixel passes a certain pre-defined threshold or intensity value. For instance, if the optical trace is normalized and fluctuates betwen [0,1] then the tissue could be defined as being 'electrically activated' when the time-series rises above or below 0.5 (depending on the fluorescent indicator and polarity of the signal).\n",
    "\n",
    "Here, we will use an example data from {cite:t}`Rybashlykov2022` in which a planar action potential wave propagates across the ventricle of a mouse heart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optimap as om\n",
    "import monochrome as mc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "filename = om.download_example_data(\"doi:10.5281/zenodo.5557829/mouse_41_120ms_control_iDS.mat\")\n",
    "video = om.load_video(filename)\n",
    "metadata = om.load_metadata(filename)\n",
    "print(f\"Loaded video with shape {video.shape} and metadata {metadata}\")\n",
    "frequency = metadata[\"frequency\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `mouse_41_120ms_control_iDS.mat` file from the [Zenodo dataset](https://doi.org/10.5281/zenodo.5557829) shows a induced pacing beats in a mouse heart. The {func}`load_metadata` function loads the metadata from the MATLAB file, in this case the acquisition frame rate. We visualize the video using [Monochrome](https://github.com/sitic/Monochrome):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# Show video\n",
    "mc.show(video, name=filename.name, metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "mp4_file = om.download_example_data(\"mouse_41_120ms_control_MiCAM_monochrome.mp4\", silent=True)\n",
    "Video(filename=mp4_file, embed=True, html_attributes=\"controls autoplay loop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use ``optimap``'s {func}`background_mask` function to blanck out the background in the image, such that the activation map is only computed for pixels showing tissue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove background by masking\n",
    "mask = om.background_mask(video[0], show=False)\n",
    "mask = om.image.dilate_mask(mask, iterations=5, show=False)\n",
    "om.image.show_mask(mask, video[0], title=\"Background mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "new_mask = om.interactive_mask(image=video[0], initial_mask=mask)\n",
    "om.save_mask('mouse_41_120ms_control_MiCAM_monochrome_mask.png', new_mask)\n",
    "mask = new_mask\n",
    "mask = om.load_mask('mouse_41_120ms_control_MiCAM_monochrome_mask.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_filtered = om.video.smooth_spatiotemporal(video, sigma_temporal=1, sigma_spatial=1)\n",
    "video_filtered = om.video.mean_filter(video_filtered, size_spatial=5)\n",
    "\n",
    "# Normalize the video using a pixelwise sliding window\n",
    "video_norm = om.video.normalize_pixelwise_slidingwindow(video_filtered, window_size=200)\n",
    "video_norm[:, mask] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the mouse heart was stained with the voltage-sensitive dye Di-4-ANEPPS, the tissue becomes darker when it depolarizes (negative signal / polarity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "om.show_video_pair(video, video_norm, title1=\"original video\",\n",
    "                   title2=\"normalized video\", interval=100)\n",
    "\n",
    "# Or in Monochrome:\n",
    "#\n",
    "# mc.show(video, name=\"original video\")\n",
    "# mc.show(video_norm, name=\"normalized video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "render(lambda: om.show_video_pair(video, video_norm, title1=\"original video\", title2=\"normalized video\", interval=250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossings = om.activation.find_activations(1 - video_norm, fps=frequency)\n",
    "print(f\"Found {len(crossings)} activation events at frames: {crossings}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot some of the video frames as the wave propagates across the ventricles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axs = plt.subplots(1, 6, figsize=(10, 3))\n",
    "axs[0].imshow(video[0], cmap='gray')\n",
    "axs[0].set_title('original')\n",
    "axs[0].set_axis_off()\n",
    "\n",
    "for i in range(1, 6):\n",
    "    t = i * 2\n",
    "    axs[i].imshow(video_norm[crossings[0] - 7 + t], cmap='gray', vmin=0, vmax=1)\n",
    "    axs[i].set_axis_off()\n",
    "    time = t * (1000/frequency)  # convert to ms\n",
    "    axs[i].set_title(f\"{time:.1f} ms\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute an activation map by identifying the local activation times in each pixel that correspond to when the action potential wave front passes through that pixel.\n",
    "\n",
    "## Computing Activation Maps from Pixel-wise Normalized Optical Maps\n",
    "\n",
    "We will first compute an activation map with a pixel-wise normalized video. The pixel-wise normalized video contains values between 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "om.print_properties(video_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pixel-wise normalization was sufficient as opposed to a sliding-window pixel-wise normalization, see [Tutorial 2](signal_extraction.ipynb), because we isolated a short part of the video that is only 20 frames long. In other cases it might be necessary to use a sliding-window pixel-wise normalization or a frame-wise difference video (e.g. with motion), see below.\n",
    "\n",
    "Let's plot some of the optical traces (manually selected so that they show locations which become subsequently activated):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positions = om.select_positions(video[0])\n",
    "positions =  [(134, 101), (15, 93), (94, 99), (53, 97)]\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
    "om.trace.show_positions(positions, video[0], ax=axs[0])\n",
    "traces = om.extract_traces(video_norm,\n",
    "                           positions,\n",
    "                           size=10,\n",
    "                           fps=frequency,\n",
    "                           ax=axs[1])\n",
    "axs[1].axhline(y=0.5, color='r', linestyle='dashed', label='threshold')\n",
    "axs[1].text(0.03, 0.52, 'threshold', color='r')\n",
    "plt.xlim(0, 0.12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use ``optimap``'s {func}`compute_activation_map` function to automatically compute a two-dimensional activation map which shows the local activation times in every pixel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = crossings[7]\n",
    "activation_map = om.compute_activation_map(video_norm[idx - 7:idx + 10], inverted=True, fps=frequency, vmax=13)\n",
    "levels = [3, 6, 9, 12, 15]\n",
    "video_norm2 = video_norm.copy()\n",
    "video_norm2[np.isnan(video_norm2)] = np.nanmean(video_norm2)\n",
    "video_norm2 = om.video.mean_filter(video_norm2, size_spatial=5)\n",
    "activation_map = om.compute_activation_map(video_norm[idx - 9:idx + 10], inverted=True, fps=frequency, vmax=18, show_contours=True, contour_levels=levels)\n",
    "activation_map = om.compute_activation_map(video_norm2[idx - 9:idx + 10], inverted=True, fps=frequency, vmax=18, show_contours=True, contour_levels=levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we used the argument `inverted=True` due to the negative polarity of the signal ($- \\Delta F / F$). If me had manually inverted the video beforehand or with calcium imaging data this would not be necessary. The range of local activation times can be displayed with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "om.print_properties(activation_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the local activation times are given in milliseconds (based on argument `fps=500`) and they range between 0ms and 36ms. The function {func}`compute_activation_map` uses {func}`show_image` to plot the activation map (which can be disabled with argument `show=False`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "om.show_activation_map(activation_map, cmap=\"jet\", title='Activation Map', show_colorbar=True, colorbar_title='Activation Time [ms]', vmax=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have plotted the activation map using the `jet` colormap, here are some other options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(8, 3))\n",
    "om.show_activation_map(activation_map, cmap='jet', show_colorbar=True, title='cmap=jet', ax=axs[0], colorbar_title=None)\n",
    "om.show_activation_map(activation_map, cmap='magma', show_colorbar=True, title='cmap=magma', ax=axs[1], colorbar_title=None)\n",
    "om.show_activation_map(activation_map, cmap='twilight_shifted', show_colorbar=True, title='cmap=twilight_shifted', ax=axs[2], colorbar_title=None)\n",
    "plt.suptitle('Activation maps with different colormaps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Activation Maps from Frame-Wise Difference Optical Maps\n",
    "\n",
    "In [Tutorial 2](signal_extraction.ipynb), we introduced the frame-wise difference method to emphasize sudden temporal changes in a video. Sudden temporal changes are caused by upstrokes of the action potential or calcium transients and the frame-wise difference filter is therefore ideally suited to visualize wavefronts as they propagate across the tissue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_diff = om.video.temporal_difference(video_warped, 5)\n",
    "video_diff[:, mask] = np.nan\n",
    "video_diff_norm = om.video.normalize_pixelwise(video_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frame-wise difference approach enhances action potential upstroke, see the following video with temporal difference in the middle and our previous pixel-wise normalized video on the right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "om.show_videos([video, video_diff_norm, video_warped_norm],\n",
    "               titles=[\"original\", \"warped, frame-wise diff\", \"warped, normalized\"],\n",
    "               interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "render(lambda: om.show_videos([video, video_diff_norm, video_warped_norm],\n",
    "               titles=[\"original\", \"warped, frame-wise diff\", \"warped, normalized\"],\n",
    "               interval=250))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the wavefront as an overlay over the raw (motion-stabilized) video. We will need to further post-process the data as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_diff[video_diff > 0] = 0\n",
    "video_diff_norm = om.video.normalize_pixelwise(-video_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The action potential upstroke overlaid onto the raw video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "om.video.show_video_overlay(video_warped,\n",
    "                            overlay=video_diff_norm,\n",
    "                            vmin_overlay=-1,\n",
    "                            vmax_overlay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "render(lambda: om.video.show_video_overlay(video_warped, video_diff_norm, vmin_overlay=-1, vmax_overlay=1, interval=200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Contour Lines to Activation Maps\n",
    "\n",
    "Contour lines are a powerful visualization tool that can help highlight the wavefront propagation. They connect points with the same activation time, making it easier to visualize the speed and direction of propagation. Let's add contour lines to our activation map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with the activation map and contour lines\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Show the activation map as a colored background\n",
    "im = ax.imshow(activation_map, cmap='jet')\n",
    "\n",
    "# Add contour lines with labels\n",
    "# The levels parameter controls at which activation times contour lines are drawn\n",
    "contour = ax.contour(activation_map, levels=np.arange(0, 35, 5), colors='white', linewidths=1)\n",
    "\n",
    "# Add labels to the contour lines (time in ms)\n",
    "plt.clabel(contour, inline=True, fontsize=8, fmt='%1.0f ms')\n",
    "\n",
    "# Add colorbar and title\n",
    "cbar = plt.colorbar(im, ax=ax)\n",
    "cbar.set_label('Activation Time [ms]')\n",
    "ax.set_title('Activation Map with Contour Lines')\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also combine contour lines with a raw image to visualize the propagation path over the heart tissue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure showing both the raw image and the contour lines\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Show the raw image as background\n",
    "ax.imshow(video_warped[0], cmap='gray')\n",
    "\n",
    "# Add contour lines on top\n",
    "# Use more levels for finer detail\n",
    "contour_levels = np.arange(0, 35, 3)\n",
    "contour = ax.contour(activation_map, levels=contour_levels, \n",
    "                    cmap='jet', linewidths=1.5, alpha=0.8)\n",
    "\n",
    "# Add a colorbar\n",
    "cbar = plt.colorbar(contour, ax=ax)\n",
    "cbar.set_label('Activation Time [ms]')\n",
    "\n",
    "ax.set_title('Activation Contour Lines Overlaid on Tissue')\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customizing Contour Visualization\n",
    "\n",
    "You can customize various aspects of the contour lines to highlight different features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a more customized visualization\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Apply a different colormap to the background\n",
    "im = ax.imshow(activation_map, cmap='viridis', alpha=0.7)\n",
    "\n",
    "# Create contour lines with custom levels and style\n",
    "contour_levels = np.arange(0, 35, 2.5)  # More contour lines for finer detail\n",
    "contour = ax.contour(activation_map, levels=contour_levels, \n",
    "                     colors='white', linewidths=0.8)\n",
    "\n",
    "# Add contour labels selectively (only to some contour lines)\n",
    "plt.clabel(contour, inline=True, fontsize=8, \n",
    "           fmt='%1.0f ms', levels=np.arange(0, 35, 5))\n",
    "\n",
    "# Add masked tissue outline\n",
    "# First, create a mask boundary line\n",
    "mask_boundary = ax.contour(mask, levels=[0.5], colors='red', linewidths=1.5)\n",
    "\n",
    "# Add colorbar and annotations\n",
    "cbar = plt.colorbar(im, ax=ax)\n",
    "cbar.set_label('Activation Time [ms]')\n",
    "ax.set_title('Detailed Activation Map with Contour Lines')\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting Isochronal Lines for Analysis\n",
    "\n",
    "You can also extract the contour lines as paths for further analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create contour lines for analysis\n",
    "contour_set = plt.contour(activation_map, levels=np.arange(0, 35, 5))\n",
    "\n",
    "# No need to show this plot - just getting the contours\n",
    "plt.close()\n",
    "\n",
    "# Extract paths from a specific contour level (e.g., 15 ms isochronal line)\n",
    "contour_level_index = 3  # This is the index for the 15 ms contour in our sequence\n",
    "contour_paths = contour_set.collections[contour_level_index].get_paths()\n",
    "\n",
    "print(f\"Number of paths in the 15 ms contour: {len(contour_paths)}\")\n",
    "\n",
    "# Example: Plot just the 15 ms isochronal line on the raw image\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.imshow(video_warped[0], cmap='gray')\n",
    "\n",
    "for path in contour_paths:\n",
    "    # Extract vertices of the path\n",
    "    vertices = path.vertices\n",
    "    ax.plot(vertices[:, 0], vertices[:, 1], 'r-', linewidth=2, label='15 ms isochrone')\n",
    "    \n",
    "# Remove duplicate labels\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "plt.legend(by_label.values(), by_label.keys())\n",
    "\n",
    "ax.set_title('15 ms Isochronal Line')\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These contour lines are especially useful for estimating conduction velocity and identifying areas of slow conduction or conduction block in the heart tissue. </file>\n",
    "\n",
    "This enhancement adds a comprehensive section about contour lines to the activation maps tutorial. The additions include:\n",
    "\n",
    "Basic contour line overlay on the activation map\n",
    "Overlaying contour lines on the original tissue image\n",
    "Creating more customized contour visualizations with different styling options\n",
    "Extracting isochronal lines (contour paths) for further analysis\n",
    "These examples demonstrate various ways to visualize wave propagation with contour lines, which is an essential technique when analyzing cardiac activation patterns. The contour lines make it easier to see how the activation wave spreads across the tissue and can help identify conduction disorders or other cardiac abnormalities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now compute an activation map from the frame-wise difference video:\n",
    "\n",
    "```{warning}\n",
    "This tutorial is currently work in progress. We will add more information soon.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "test_name": "notebook1"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
