{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "source": [
    "```{currentmodule} optimap\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Code snippet for rendering animations in the docs\n",
    "from IPython.display import HTML\n",
    "import warnings\n",
    "import matplotlib\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def render_ani_func(f):\n",
    "    om.utils.disable_interactive_backend_switching()\n",
    "    plt.switch_backend('Agg')\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        ani = f()\n",
    "    %matplotlib inline\n",
    "    om.utils.enable_interactive_backend_switching()\n",
    "\n",
    "    vid = HTML(ani.to_html5_video())\n",
    "    plt.close('all')\n",
    "    return vid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "source": [
    "```{tip}\n",
    "Download this tutorial as a {download}`Jupyter notebook <converted/signal_extraction.ipynb>`, or a {download}`python script <converted/signal_extraction.py>` with code cells.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: Measurement of Fluorescent Signals and Waves\n",
    "\n",
    "This tutorial will cover the measurement of fluorescent signals and wave dynamics from cardiac optical mapping data more generally. In [Tutorial 1](basics.ipynb) we already loaded and displayed video data, performed numerical motion tracking and motion-stabilization, performed some post-processing, and displayed action potential waves. In this tutorial, we will cover the post-processing routines used to extract and display the optical signals in more detail. Note that this tutorial covers post-processing routines that can only be applied to motion-inhibited tissues. The motion-inhibition can result from either pharmacological excitation-contraction uncoupling with agents such as Blebbistatin or from numerical motion correction. Therefore, you could analyze your own video data, even if it was acquired with Blebbistatin, following the steps outlined in this tutorial. We first repeat the steps from the previous tutorial by loading the experimental data and performing motion correction. Accordingly, if you analyze videos that were acquired with Blebbistatin, you can simply skip the motion correction steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "import optimap as om\n",
    "import numpy as np\n",
    "\n",
    "filepath = om.utils.retrieve_example_data('Example_02_VF_Rabbit_Di-4-ANEPPS_Basler_acA720-520um.npy')\n",
    "# alterantively set filepath = '/folder_on_your_computer/Example_02_VF_Rabbit_Di-4-ANEPPS_Basler_acA720-520um.npy'\n",
    "video = om.load_video(filepath)\n",
    "warped = om.motion_compensate(video,\n",
    "                              contrast_kernel=5,\n",
    "                              presmooth_spatial=1,\n",
    "                              presmooth_temporal=1)\n",
    "om.video.play(warped, title=\"recording without motion\", skip_frame=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Hidden, same as above but shorten the video slightly\n",
    "\n",
    "import optimap as om\n",
    "import numpy as np\n",
    "\n",
    "filepath = om.utils.retrieve_example_data('Example_02_VF_Rabbit_Di-4-ANEPPS_Basler_acA720-520um.npy')\n",
    "video = om.load_video(filepath, use_mmap=True)[:500]\n",
    "filepath = om.utils.retrieve_example_data('Example_02_VF_Rabbit_Di-4-ANEPPS_Basler_acA720-520um_warped.npy', silent=True)\n",
    "warped = om.load_video(filepath, use_mmap=True)[:500]\n",
    "render_ani_func(lambda: om.video.play(warped, title=\"recording without motion\", skip_frame=1, interval=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For better visualization in the next steps we'll need a mask of the background. Here we use {func}`background_mask` to create a mask of the background from the first frame of the data using an automatic threshold.\n",
    "\n",
    "Pixels in red are considered background (value of `True`), and pixels in blue are considered foreground (value of `False`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_mask = om.background_mask(warped[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fluorescence wave isolation\n",
    "\n",
    "```{warning}\n",
    "This tutorial is currently work in progress. We will add more information soon.\n",
    "```\n",
    "\n",
    "We will cover two possible ways to extract the fluorescence wave dynamics:\n",
    "\n",
    "1. Using sliding window normalization. This method conserves the shape of the action potential and normalizes the signal to [0, 1] using a sliding window. However, it can be sensitive to noise and changes of the base fluorescence due to inhomogeneous illumination when using motion correction.\n",
    "2. Using a frame difference approach. This method is more robust, however it does not conserve the shape of the action potential. It is useful to visualize the propagation the front of the action potential waves.\n",
    "\n",
    "\n",
    "### Sliding window normalization\n",
    "\n",
    "The sliding/rolling window normalization performs a pixel-based normalization of the signal to [0, 1] within a short temporal window for each time point. The function {func}`video.normalize_pixelwise_slidingwindow` performs this operation, by computing the following equation for each pixel $(x, y)$ and frame $t$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\text{signal}_{\\text{norm}}(t, x, y) = \\frac{\\text{signal}(t, x, y) - \\text{min}_{t' \\in [t - w/2, t + w/2]} \\text{signal}(t', x, y)}{\\text{max}_{t' \\in [t - w/2, t + w/2]} \\text{signal}(t', x, y) - \\text{min}_{t' \\in [t - w/2, t + w/2]} \\text{signal}(t', x, y)}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $w$ is the window size.\n",
    "\n",
    "Let's use a window size $w$ of 60 frames (120 ms) for this example and mask out the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "norm_warped = om.video.normalize_pixelwise_slidingwindow(warped, window_size=60)\n",
    "norm_warped[:, background_mask] = np.nan\n",
    "\n",
    "om.video.play(norm_warped, title=\"sliding window normalization\", interval=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "norm_warped = om.video.normalize_pixelwise_slidingwindow(warped, window_size=60)\n",
    "norm_warped[:, background_mask] = np.nan\n",
    "\n",
    "render_ani_func(lambda: om.video.play(norm_warped, title=\"sliding window normalization\", interval=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "alpha = om.video.normalize(norm_warped, vmin=0.5, vmax=0)\n",
    "om.video.play_with_overlay(warped, 1-norm_warped, alpha=alpha, vmin_overlay=0, vmax_overlay=1, interval=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "alpha = om.video.normalize(norm_warped, vmin=0.5, vmax=0)\n",
    "render_ani_func(lambda: om.video.play_with_overlay(warped, (1-norm_warped), alpha=alpha, interval=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal difference\n",
    "\n",
    "The temporal difference approach computes the difference between frames at time $t$ and $t - n$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\text{signal}_{\\text{diff}}(t, x, y) = \\text{signal}(t, x, y) - \\text{signal}(t - n, x, y)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $\\Delta t$ is the time difference between frames. This method is more robust, however it does generally not conserve the shape of the action potential. Rather, it isolates the front of the fluorescent waves.\n",
    "\n",
    "Let's use $n = 10$ for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "n = 5\n",
    "diff = om.video.temporal_difference(warped, n)\n",
    "diff[:, background_mask] = np.nan\n",
    "abs_max = 0.33*np.nanmax(np.abs(diff))\n",
    "om.video.play(diff, title=\"temporal difference\", cmap=\"PiYG\", vmin=-abs_max, vmax=abs_max, interval=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "diff[diff > 0] = 0\n",
    "om.video.play(diff, title=\"temporal difference\", cmap=\"PiYG\", vmin=-abs_max, vmax=abs_max, interval=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "om.video.play2(norm_warped, diff, title1=\"Sliding Window\", title2=\"Frame Difference\", vmin1=0, vmax1=1, cmap2='gray', vmin2=0.2*np.nanmin(diff), vmax2=0, interval=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "diff_norm = om.video.normalize_pixelwise_slidingwindow(diff, window_size=60)\n",
    "om.video.play2(norm_warped, diff_norm, vmin1=0, vmax1=1, cmap2='gray', vmin2=0, vmax2=1, interval=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "diff = om.video.temporal_difference(warped, 10)\n",
    "diff[diff > 0] = 0\n",
    "diff[:, background_mask] = np.nan\n",
    "diff_norm = om.video.normalize_pixelwise_slidingwindow(-diff, window_size=60)\n",
    "om.video.play_with_overlay(warped, diff_norm, vmin_overlay=-1, vmax_overlay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "diff = om.video.temporal_difference(warped, 10)\n",
    "diff[diff > 0] = 0\n",
    "diff[:, background_mask] = np.nan\n",
    "diff_norm = om.video.normalize_pixelwise_slidingwindow(-diff, window_size=60)\n",
    "render_ani_func(lambda: om.video.play_with_overlay(warped, diff_norm, vmin_overlay=-1, vmax_overlay=1, interval=20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "test_name": "notebook1"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
