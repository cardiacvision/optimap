{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "source": [
    "```{currentmodule} optimap\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Code snippet for rendering animations in the docs\n",
    "from IPython.display import HTML\n",
    "import warnings\n",
    "import matplotlib\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "\n",
    "def render_ani_func(f):\n",
    "    om.utils.disable_interactive_backend_switching()\n",
    "    plt.switch_backend('Agg')\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        ani = f()\n",
    "    %matplotlib inline\n",
    "    om.utils.enable_interactive_backend_switching()\n",
    "\n",
    "    vid = HTML(ani.to_html5_video())\n",
    "    plt.close('all')\n",
    "    return vid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "source": [
    "```{tip}\n",
    "Download this tutorial as a {download}`Jupyter notebook <converted/activation.ipynb>`, or a {download}`python script <converted/activation.py>` with code cells. We highly recommend using [Visual Studio Code](#vscode) to execute this tutorial.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 4: Activation Maps\n",
    "\n",
    "This tutorial will discuss how to compute local activation times and activation maps from cardiac optical mapping data using ``optimap``. Local activation times (often referred to as LATs) are times specified in frames or milliseconds at which the tissue became electrically activated. Computing local activation times corresponds to determining when the optical signal in a given pixel passes a certain pre-defined threshold or intensity value. For instance, if the optical trace is normalized and fluctuates betwen [0,1] and an action potential darkens the image (this is the convention that we use in Tutorials 1 and 2), then the tissue could be defined as being electrically 'activated' when the time-series goes below 0.5. We will discuss several examples in this tutorial.\n",
    "\n",
    "First, we load and preprocess an example dataset in which a planar action potential wave propagates across the ventricles of a rabbit heart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optimap as om\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "filename = om.utils.retrieve_example_data('Example_01_Sinus_Rabbit_Basler.npy')\n",
    "video = om.load_video(filename)\n",
    "video = om.video.rotate_left(video)\n",
    "video=video[:20,:,:]\n",
    "om.print_properties(video)\n",
    "video_warped = om.motion.motion_compensate(video, 5, ref_frame=0)\n",
    "video_warped_norm = om.video.normalize_pixelwise(video_warped)\n",
    "om.print_properties(video_warped_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the rabbit heart was stained with the voltage-sensitive dye Di-4-ANEPPS, the tissue becomes darkens when the tisue depolarizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "om.video.play2(video, video_warped_norm, title1=\"original video\", title2=\"warped, normalized video\", interval=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "render_ani_func(lambda: om.video.play2(video, video_warped_norm, title1=\"original video\", title2=\"warped, normalized video\", interval=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot some of the video frames as the wave propagates across the ventricles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axarr = plt.subplots(1, 5)\n",
    "axarr[0].imshow(video[0, :, :], cmap='gray')\n",
    "axarr[1].imshow(video_warped_norm[1,:,:], cmap='gray', vmin=0, vmax=1)\n",
    "axarr[2].imshow(video_warped_norm[6,:,:], cmap='gray', vmin=0, vmax=1)\n",
    "axarr[3].imshow(video_warped_norm[10,:,:], cmap='gray', vmin=0, vmax=1)\n",
    "axarr[4].imshow(video_warped_norm[14,:,:], cmap='gray', vmin=0, vmax=1)\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's also plot some of the optical traces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = [(192, 167), (204, 141), (118, 158), (183, 267)]\n",
    "traces = om.extract_traces(video_warped_norm, positions, size=3, show=True, fps=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute an activation map by identifying the timepoints in each pixel that correspond to when the action potential wave front passes through that pixel.\n",
    "\n",
    "## Computing Activation Maps from Pixel-wise Normalized Optical Maps\n",
    "\n",
    "The pixel-wise normalized video contains values between 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "om.print_properties(video_warped_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first invert the video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_warped_norm = video_warped_norm*-1.0+1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot some of the optical traces (manually selected so that they show locations which become subsequently activated):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions =  [(227, 181), (199, 162), (213, 171), (240, 189), (176, 146), (188, 153)]\n",
    "traces = om.extract_traces(video_warped_norm, positions, size=3, show=True, fps=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use ``optimap``'s {func}`compute_activation_map` function to automatically compute a two-dimensional activation map which shows the local activation times (here in frames because fps is unspecified):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_map = om.activation.compute_activation_map(video_warped_norm, threshold=0.5, fps=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The range of local activation times can be displayed with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "om.print_properties(activation_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the activation map using 2 differrent colormaps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axarr = plt.subplots(1, 3)\n",
    "axarr[0].imshow(video[0, :, :], cmap='gray')\n",
    "axarr[1].imshow(activation_map, cmap='hsv', vmin=0, vmax=20)\n",
    "axarr[2].imshow(activation_map, cmap='jet', vmin=0, vmax=20)\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see a continuois activation of the tissue.\n",
    "\n",
    "```{warning}\n",
    "This tutorial is currently work in progress. We will add more information soon.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video_diff = om.video.temporal_difference(video_warped, 5)\n",
    "#video_diff[:, background_mask] = np.nan"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "test_name": "notebook1"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
