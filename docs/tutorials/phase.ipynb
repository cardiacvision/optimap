{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "source": [
    "```{currentmodule} optimap\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "from optimap.utils import jupyter_render_animation as render"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "source": [
    "```{tip}\n",
    "Download this tutorial as a {download}`Jupyter notebook <converted/phase.ipynb>`, or a {download}`python script <converted/phase.py>` with code cells. We highly recommend using [Visual Studio Code](#vscode) to execute this tutorial.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 9: Phase and Singularities during VF\n",
    "\n",
    "In this tutorial, we will learn how to compute phase maps of action potential vortex waves during ventricular fibrillation (VF). Using the phase maps, we will compute and track phase singularities across the epicardial surface of an isolated intact rabbit heart during VF. Phase singularities (PS) indicate rotational core regions of reentrant vortex waves (spiral waves) and can be used to characterize the complexity of VF or to document interactions of reentrant waves with the substrate. For example, a higher number of PS can indicate more aggresive episodes of VF, moving PS are associated with meandering spiral waves and high motility, and PS can attach to scar tissue and other heterogeneities. `optimap` provides all routines which are necessary to compute and filter phase videos, and calculate and track phase singularities. Similar analysis was performed in {footcite:t}`Christoph2018,Lebert2021` among many other publications.\n",
    "\n",
    "Here we use the VF example file from [Tutorial 1](basics.ipynb) and compensate the residual contractile motion to work with a video without motion. We then compute a pixel-wise normalized motion-stabilized video and mask out the background to focus on the electrical dynamics on the epicardial surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optimap as om\n",
    "import numpy as np\n",
    "\n",
    "filepath = om.download_example_data('VF_Rabbit_1.npy')\n",
    "video = om.load_video(filepath, frames=500)\n",
    "video_warped = om.motion_compensate(video,\n",
    "                                    contrast_kernel=5,\n",
    "                                    presmooth_spatial=1,\n",
    "                                    presmooth_temporal=1)\n",
    "\n",
    "video_warped_normalized = om.video.normalize_pixelwise_slidingwindow(video_warped, window_size=60)\n",
    "\n",
    "mask = om.background_mask(video_warped[0], show=False)\n",
    "video_warped_normalized[:, mask] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pixel-wise normalized motion-stabilized video displays action potential vortex waves as black waves (when using a black-and-white colormap):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "om.show_video(video_warped_normalized, interval=40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "render(lambda: om.show_video(video_warped_normalized, interval=40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will first compute and display a phase video from the pixel-wise normalized video. Alternatively to a pixel-wise normalized video one could also compute phase maps from a frame-wise differentiated video, see below. We will then smooth the phase video using spatio-temporal phase smoothing filters, and ,lastly, calculate and track phase singularities through the video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Phase Videos\n",
    "\n",
    "Phase videos can be computed from normalized video data in which the optical signals fluctuate between [0,1]. Because we already normalized the video above, `optimap`'s {func}`compute_phase` function can compute the phase automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_phase = om.phase.compute_phase(video_warped_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The phase angle was computed for each time-series in the video individually using the Hilbert transform. All values in the resulting phase video lie on the interval [$-\\pi$, $\\pi$]. Now, let's have a look at the phase video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "om.show_video(video_phase, title='phase video', cmap='hsv', interval=40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "render(lambda: om.show_video(video_phase, title='phase video', cmap='hsv', interval=40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose the continuous colormap 'hsv' which displays both $-\\pi$ and $\\pi$ in red. The 'hsv' colormap has the following advantages: 1) there is no discontinuity at the phase shift from $-\\pi$ to $\\pi$, 2) all lines of equal phase are displayed by lines of equal color, 3) it is easier to identify pinwheel patterns or 'rotors'. \n",
    "\n",
    "The phase video contains a lot of noise as it was derived from the raw pixel-wise normalized video. In order to remove the noise in the phase video, we will now apply different phase filters which convert the phase video data into complex phase data and operate on this complex data:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\phi(t, x, y) \\rightarrow \\cos{\\phi}(t,x,y) + i \\cdot \\sin{\\phi}(t,x,y)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "First, we will use a phase coherence filter {func}`phasefilter_angle_threshold`, which will detect and remove outliers in the phase video by computing the complex order parameter $r$ for each pixel and removing pixels with low $r$ (defined by threshold parameter, typically 0.8 - 0.9).The complex order parameter $r$ is calculated by summing the complex vectors describing the phase of each pixel on the unit circle within a small disc-shaped region around the pixel and computing their cumulative magnitude:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    r \\cdot e^{\\phi} = \\frac{1}{N} \\sum \\limits_i^N e^{i\\phi_j}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $j = 1,...,N$ is the number of complex phase values within a spatio-temporal kernel around each pixel with diameter $2 \\dot wx + 1$ pixels and a temporal window size of $2 \\cdot wt + 1$ video frames, see also {footcite:t}`Lebert2021`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_phase_filtered = om.phase.phasefilter_angle_threshold(video_phase, wx=3, wy=3, wt=1, tr_angle=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the resulting filtered phase video all outliers were replaced with NaNs, which are being displayed as white pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "om.show_video(video_phase_filtered, title='removed outliers', cmap='hsv', interval=40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "render(lambda: om.show_video(video_phase_filtered, title='removed outliers', cmap='hsv', interval=40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can infill all NaN pixels with interpolated phase values from the surrounding tissue, which we compute using the {func}`phasefilter_fillsmooth` function that operates on the complex phase values:\n",
    "\n",
    "```{warning}\n",
    "This tutorial is currently work in progress. We will add more information soon.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further reading:\n",
    "\n",
    "```{footbibliography}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "test_name": "notebook1"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
