{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "source": [
    "```{currentmodule} optimap\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "from optimap.utils import jupyter_render_animation as render"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "source": [
    "```{tip}\n",
    "Download this tutorial as a {download}`Jupyter notebook <converted/01_overview.ipynb>`, or a {download}`python script <converted/01_overview.py>` with code cells. We highly recommend using [Visual Studio Code](#vscode) to execute this tutorial. Alternatively, you could run the Python script in a terminal with ``python3 01_overview.py`` from the folder where the file is located.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Overview\n",
    "\n",
    "This tutorial will walk you through an basic overview of ``optimap``. ``optimap`` is a package that can be imported and used in [Python](https://en.wikipedia.org/wiki/Python_programming_language) scripts or notebooks. Download the tutorial from the link at the top of the page and follow along.\n",
    "\n",
    "Let's import ``optimap`` and name it ``om`` for short:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optimap as om"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running this command and ``optimap`` was installed correctly, there should be no further output. We now have access to all the functions in the `optimap` package, and it can then be accessed by typing `om.` followed by a specific function as shown below (e.g. `om.load_video()`). If the import produces an error then ``optimap`` was  not installed correctly, see [Installation Guide](#installing) for further details. \n",
    "\n",
    "``optimap`` relies heavily on other open-source software packages and libraries, foremost [NumPy](https://numpy.org/), which is a numerical programming library, [Matplotlib](https://matplotlib.org/), which is a library for plotting data, and [OpenCV](https://opencv.org/), which is a library for computer vision. In this example, we will import ``numpy`` and ``matplotlib`` as they will be used in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you encounter any issues with the steps above please see the [Installation Guide](https://optimap.readthedocs.io/en/latest/chapters/getting_started/) or create an [Issue](https://github.com/cardiacvision/optimap/issues) on GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a video file\n",
    "\n",
    "The following video file formats are currently supported by ``optimap``:\n",
    "\n",
    "* .tif, .tiff (TIFF) image stacks\n",
    "* Folder containing sequence of TIFF or .png (PNG) images\n",
    "* .gsd, .gsh (SciMedia MiCAM 05)\n",
    "* .rsh, .rsm, .rsd (SciMedia MiCAM ULTIMA)\n",
    "* .dat (MultiRecorder)\n",
    "* .npy (numpy array)\n",
    "* .mat (MATLAB), loads the first field in the file\n",
    "\n",
    "which can be loaded with the function {func}`load_video`, see [](io.ipynb) for further details.\n",
    "\n",
    "The code below will automatically download an example video recording from our website [cardiacvision.ucsf.edu](https://cardiacvision.ucsf.edu) and save it a folder named `optimap_example_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = om.download_example_data(\"VF_Rabbit_1.npy\")\n",
    "# alternative if for using your own data\n",
    "# filename = \"example.tif\"\n",
    "video = om.load_video(filename)\n",
    "\n",
    "om.print_properties(video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`optimap` imports video data as three-dimensional NumPy array,  where the first dimension is time and the other two dimensions are the x- and y-dimensions, respectively. This convention is used throughout the library. The function {func}`print_properties()` displays the dimensions and maximal and minimal intensity values of a video. Our example file has 1040 video frames. See {func}`load_video` for additional arguments, e.g. to load only a subset of the frames or to use memory mapping to reduce memory usage.\n",
    "\n",
    "## Playing Videos\n",
    "Videos can be viewed using either:\n",
    "1. the built-in viewer {func}`show_video` based on matplotlib\n",
    "2. [Monochrome](https://monochrome.readthedocs.io/latest/), which is a more advanced and performant viewer with better interactive features\n",
    "\n",
    "### Using the built-in Viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "om.show_video(video, title='Recording', skip_frame=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "render(lambda: om.show_video(video, title='Recording', interval=15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example video shows a fibrillating, weakly contracting rabbit heart stained with voltage-sensitive dye (Di-4-ANEPPS) imaged at 500 frames per second. Due to the staining, the action potential wave is inverted, i.e. an upstroke is observed as a negative deflection. The data is from {cite}`Chowdhary2023` and we extracted a short part of the original recording and saved the otherwise unprocessed raw video data as a numpy file (`.npy`).\n",
    "\n",
    "See API documentation for {func}`show_video` for a list of available arguments. For instance, it is possible to specify a title, a range \n",
    "(vmin=0, vmax=1) and colormap:\n",
    "```python\n",
    "om.show_video(video, title='Example video', vmin=0, vmax=1, cmap='gray', interval=20)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### Using Monochrome\n",
    "Monochrome needs to be installed separately. We will provide installation instructions soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "import monochrome as mc\n",
    "mc.show(video, \"Recording\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the [Monochrome documentation](https://monochrome.readthedocs.io) and {func}`monochrome.show` for more information. For example, click in the video to view time traces at the selected positions.\n",
    "\n",
    "## Viewing and Extracting Traces\n",
    "\n",
    "Using `optimap` it is possible to quickly extract and display optical traces from any location in a video and display them using the built-in player. With the {func}`select_traces` it is possible to interactively select, extract and view an optical trace. Click on the video image on the left to select a single position or multiple positions. Right click to remove positions. Close the window to continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "traces, positions = om.select_traces(video, size=5, fps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "positions = [(127, 147), (130, 209), (202, 136)]\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(11,4))\n",
    "om.trace.show_positions(positions, video[0], ax=axs[0])\n",
    "traces = om.trace.extract_traces(video, positions, size=5, ax=axs[1], show=True, fps=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internally {func}`select_traces` uses {func}`extract_traces`, see below. Traces can be extracted from a single pixel or from a small window surrounding the pixel. The `size` parameter controls the dimensions of the window. By default, this window is a rectangle with dimensions `(size, size)`, but it can also be set to `'disc'` using the `window` parameter, which then sets the window to a circular region with diameter `size` around the position. Use {func}`optimap.trace.set_default_trace_window` to change the default window type (e.g. by calling it before `select_traces()`, `extract_traces()` or at the beginnig of the script with `'disc'` as input parameter). The default size of the window is 5 by 5 pixels (rectangular) or a diameter of 5 pixels (disc). To get the exact pixel values without spatial averaging, set `size=1`. **Note that the traces above include strong motion artifacts.** If you would like to display the time axis in seconds rather than frames, use the `fps` (frames per second) parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = om.extract_traces(video, positions, size=1, show=True, fps=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that {func}`extract_traces` uses positions as input which you already previously selected or defined, see {func}`extract_traces` for more information. Internally {func}`extract_traces` uses {func}`show_traces` to plot traces. In general, all plotting functions in optimap have an `ax` parameter which can be used to specify a custom matplotlib axes object. For example, we can create a figure with two subplots and show the positions on the first subplot and the traces on the second subplot with milliseconds as time unit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
    "\n",
    "om.trace.show_positions(positions, video[0], ax=axs[0])\n",
    "\n",
    "x_axis_ms = (np.arange(video.shape[0]) / 500.0) * 1000\n",
    "traces = om.extract_traces(video[:300],\n",
    "                           positions,\n",
    "                           x=x_axis_ms[:300],\n",
    "                           size=5,\n",
    "                           window='disc',\n",
    "                           ax=axs[1])\n",
    "axs[1].set_xlabel('Time [ms]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the optical traces above were sampled from a raw optical mapping video that shows a fibrillating contracting heart (no Blebbistatin was used during the experiment), the traces contain strong **motion artifacts**. We will now use optimap to track the motion and to compensate these motion artifacts.\n",
    "\n",
    "## Motion Compensation\n",
    "\n",
    "`optimap` provides automatic routines for tracking and stabilizing motion in fluorescence videos. Here, the motion-stabilized videos are interchangeably referred to as warped videos, see also {footcite:t}`Christoph2018a, Lebert2022, Christoph2018, Kappadan2020, Kappadan2023, Christoph2023` for further details. Tracking motion and creating a motion-stabilized or warped video is just a few lines of code with `optimap`. The fibrillating heart from our example contracts rapidly and moves slightly. Even though the motion is small, it can have a strong effect onto the quality of the optical traces and cause motion artifacts. Motion artifacts can in many cases prevent further analysis of the data. We can use `optimap`'s {func}`motion_compensate` function to compensate the motion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "video_warped = om.motion_compensate(video,\n",
    "                                    contrast_kernel=5,\n",
    "                                    presmooth_spatial=1,\n",
    "                                    presmooth_temporal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# load pre-computed warped video to speed up docs build time\n",
    "filepath = om.utils.download_example_data('VF_Rabbit_1_warped.npy', silent=True)\n",
    "video_warped = om.load_video(filepath, use_mmap=True)[:1000]\n",
    "# fake tqdm progress bar\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "for _ in tqdm(range(1000), desc='Computing flows (CPU)'):\n",
    "    sleep(1/500.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `video_warped` is the motion-stabilized version of the original video. The other parameters are explained in more detail in [](motion_compensation). You will also find further background information about the motion tracking and compensation routines in {cite}`Christoph2018a` and {cite}`Lebert2022`. Let's view the original video and the motion-compensated video side by side using {func}`optimap.show_video_pair`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "om.show_video_pair(video,\n",
    "                   video_warped,\n",
    "                   title1=\"with motion\",\n",
    "                   title2=\"without motion\",\n",
    "                   skip_frame=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "render(lambda: om.video.play2(video, video_warped, title1=\"with motion\", title2=\"without motion\", skip_frame=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the effect of the numerical motion-stabilization when plotting the same traces as above but extract them from the warped video: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = om.extract_traces(video_warped, positions, size=5, show=True, fps=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, motion artifacts are significantly reduced: the strong baseline fluctuations are gone and action potential waves are less distorted. The residual motion artifacts vary and depend on factors such as contractile strength, fluorescent signal strength, and illumination, among others, see {cite}`Christoph2018a` and {cite}`Lebert2022` for a more detailed discussion. It is possible to further reduce motion artifacts using ratiometric imaging, see [Tutorial 4](ratiometry.ipynb). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Rendering Videos\n",
    "\n",
    "Let's save the motion-compensated recording as a tiff stack and also render it to a .mp4 video file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "om.video.save_video('warped_recording.tiff', video_warped)\n",
    "om.video.export_video('warped_recording.mp4', video_warped, fps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimap video-player functions such as {func}`optimap.show_video_pair` can also be exported to a video file:\n",
    "```python\n",
    "animation = om.show_video_pair(video, video_warped, title1='Raw', title2='Compensated')\n",
    "animation.save('Example.mp4')\n",
    "```\n",
    "See {meth}`matplotlib.animation.Animation.save` for more details and [Tutorial 13](io.ipynb) for more information on how to export video files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Action Potential Waves\n",
    "\n",
    "In this example, we stained the heart with the voltage-sensitive fluorescent dye Di-4-ANEPPS. Together with an appropriate bandpass filter, Di-4-ANEPPS produces a slight decrease in the measured fluorescence when the tissue depolarizes. Accordingly, in order to visualize action potential waves, this small optical signal needs to be amplified (numerically). One way to achieve this is to normalize the optical traces 'pixel-wise': each time-series measured in a single pixel is normalized individually. In simple terms, when normalizing an optical trace one divides each value of the time-series by the maximal value found in the entire time-series and subtracts the minimum of the time-series. This removes the baseline of the time-series and all values subsequently fluctuate between 0 and 1. In our case, the depolarized phase of the action potential corresponds to values close to 0 and the diastolic interval to values close to 1. Correspondingly, the action potential wave darkens the video image. `optimap` has several built-in routines, which perform these normalization steps automatically. A more detailed explanation of visualizing action potential or calcium waves with different post-processing and normalization functions is given in [Tutorial 2](signal_extraction.ipynb). \n",
    "\n",
    "### Sliding-window Normalization\n",
    "\n",
    "We can compute a 'pixel-wise normalized video' using `optimap`'s rolling- or sliding-window normalization function ({func}`video.normalize_pixelwise_slidingwindow`), see [Tutorial 2](signal_extraction.ipynb) for more information. This function is applied to the motion-stabilized or warped video. We slide a short temporal window over the time-series extracted from this video and perform the normalization sequentially for one value after another with the corresponding local maxima and minima. The `window_size` parameter controls the length of the sliding window, which needs to be adjusted to the period of the action potential or calcium waves. Here, we use a window size of 60 frames (120 ms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_warped_normalized = om.video.normalize_pixelwise_slidingwindow(video_warped, window_size=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we display the motion-stabilized warped video, we mask out regions that do not show tissue using `optimap`'s {func}`optimap.background_mask`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = om.background_mask(video_warped[0])\n",
    "video_warped_normalized[:, mask] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a grayscale colormap, action potential waves can be visualized as black/dark waves due to the pixel-wise normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "om.video.play(video_warped_normalized, interval=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "render(lambda: om.video.play(video_warped_normalized, interval=40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we demonstrated that one can visualize vortex-like rotating action potential waves across the surface of a moving fibrillating heart using optical mapping. The action potential waves were imaged on the (slightly) contracting, fibrillating heart surface in a co-moving frame of reference.\n",
    "\n",
    "Further reading:\n",
    "\n",
    "```{footbibliography}\n",
    "```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "test_name": "notebook1"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
