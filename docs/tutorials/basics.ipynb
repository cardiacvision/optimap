{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "source": [
    "```{currentmodule} optimap\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Code snippet for rendering animations in the docs\n",
    "from IPython.display import HTML\n",
    "import warnings\n",
    "import matplotlib\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "\n",
    "def render_ani_func(f):\n",
    "    om.utils.disable_interactive_backend_switching()\n",
    "    plt.switch_backend('Agg')\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        ani = f()\n",
    "    %matplotlib inline\n",
    "    om.utils.enable_interactive_backend_switching()\n",
    "\n",
    "    vid = HTML(ani.to_html5_video())\n",
    "    plt.close('all')\n",
    "    return vid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "source": [
    "```{tip}\n",
    "Download this tutorial as a {download}`Jupyter notebook <converted/basics.ipynb>`, or a {download}`python script <converted/basics.py>` with code cells.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Basics\n",
    "\n",
    "This tutorial will walk you through the basics of using the `optimap` package.\n",
    "\n",
    "First, let's import optimap and the other packages we will need:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optimap as om\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a video file\n",
    "\n",
    "We now have access to all the functions in the `optimap` package. Use the function {func}`optimap.load_video` to load a video file. The following file formats are supported:\n",
    "\n",
    "* .tif, .tiff (TIFF stack)\n",
    "* .dat (MultiRecorder)\n",
    "* .gsd, .gsh (SciMedia MiCAM 05)\n",
    "* .rsh, .rsm, .rsd (SciMedia MiCAM ULTIMA)\n",
    "* .npy (numpy array)\n",
    "* .mat (MATLAB), loads the first field in the file\n",
    "\n",
    "Here, we first download a sample recording of a beating Rabbit heart stained with the voltage-sensitive dye di-4-ANEPPS was acquired at 500 fps using a Basler acA720-520um camera. The action potentials are inverted, i.e. an upstroke is observed as a negative deflection. We have extracted a short section of the original recording and saved the raw data as a numpy file (`.npy`). Experimenters: Jan Lebert, Shrey Chowdhary & Jan Christoph (University of California, San Francisco, USA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = om.utils.retrieve_example_data('Example_02_VF_Rabbit_Di-4-ANEPPS_Basler_acA720-520um.npy')\n",
    "video = om.load_video(filepath)\n",
    "\n",
    "om.print_properties(video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimap imports videos as numpy arrays with the shape (Time, Height, Width). This convention is used throughout the library. See {func}`load_video` for additional arguments, e.g. to load only a subset of the frames or to use memory mapping to reduce memory usage.\n",
    "\n",
    "```python\n",
    "video = om.load_video('Example.dat', start_frame=100, frames=1000, step=2, use_mmap=True)\n",
    "```\n",
    "\n",
    "For some file formats, optimap can also load the corresponding metadata using {func}`load_metadata`. For example, the following code loads the metadata of a MiCAM ULTIMA recording:\n",
    "\n",
    "```python\n",
    "metadata = om.load_metadata('Example.rsh')\n",
    "```\n",
    "\n",
    "To crop, rotate, or flip a video see {mod}`optimap.video` for a list of available functions.\n",
    "\n",
    "## Playing videos\n",
    "Videos can be viewed using either:\n",
    "1. the built-in viewer {func}`play_video` based on matplotlib\n",
    "2. using Monochrome, which is a more advanced viewer and allows for more interactivity\n",
    "\n",
    "### Using the built-in viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "om.play_video(video);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "render_ani_func(lambda: om.video.play(video))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See API documentation for {func}`play_video` for a list of available arguments, e.g.:\n",
    "```python\n",
    "om.play_video(video, title='Example video', vmin=0, vmax=1, cmap='gray', interval=20)\n",
    "```\n",
    "\n",
    "\n",
    "### Using Monochrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "import monochrome as mc\n",
    "mc.show(video, \"raw video\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the {doc}`monochrome` documentation and {func}`monochrome.show` for more information. For example, click in the video to view time traces at the selected positions.\n",
    "\n",
    "## Viewing and extracting traces\n",
    "\n",
    "Time traces can be viewed and extracted interactively using the {func}`select_traces` function. Click on the image to select positions, right click to remove positions. Close the window to continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "traces, positions = om.select_traces(video, size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "positions = [(127, 147), (130, 209), (202, 136)]\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(11,4))\n",
    "om.trace.show_positions(video[0], positions, ax=axs[0])\n",
    "traces = om.trace.extract_traces(video, positions, size=5, ax=axs[1], show=True, fps=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traces are averaged spatially over a small window surrounding the chosen location, the `size` parameter controls the dimensions of the window. By default, this window is a rectangle with dimensions `(size, size)`. In this case (the default), the window is 5 by 5 pixels.\n",
    "\n",
    "To get the exact pixel values without spatial averaging, set `size=1`.\n",
    "\n",
    "If you'd like to display the time axis in seconds rather than frames, use the `fps` (frames per second) parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = om.extract_traces(video, positions, size=1, show=True, fps=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `window` parameter can be used to define the window function, `'disc'` uses a circular region with diameter `size` around the position. See {func}`select_traces` for more information and {func}`optimap.trace.set_default_trace_window` to change the default window type.\n",
    "\n",
    "Internally {func}`extract_traces` uses {func}`show_traces` to plot traces. In general, all plotting functions in optimap have an `ax` parameter which can be used to specify a custom matplotlib axes object.\n",
    "\n",
    "For example, we can create a figure with two subplots and show the positions on the first subplot and the traces on the second subplot with milliseconds as time unit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(10,5))\n",
    "\n",
    "om.trace.show_positions(video[0], positions, ax=axs[0])\n",
    "\n",
    "x_axis_ms = (np.arange(video.shape[0]) / 500.0) * 1000\n",
    "traces = om.extract_traces(video[:300],\n",
    "                           positions,\n",
    "                           x=x_axis_ms[:300],\n",
    "                           size=5,\n",
    "                           window='disc',\n",
    "                           ax=axs[1],\n",
    "                           show=True)\n",
    "axs[1].set_xlabel('Time [ms]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motion Compensation\n",
    "\n",
    "The heart is beating and slightly moving during this recording. Even though the motion is small, it can have a strong effect on the time traces in the form of motion artifacts and prevent further analysis. We can use the {func}`motion_compensate` function to compensate for the motion using the steps described in {cite}`Christoph2018a` and {cite}`Lebert2022`. See [](motion_compensation) for detailed information and examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warped = om.motion_compensate(video,\n",
    "                              contrast_kernel=5,\n",
    "                              presmooth_spatial=1,\n",
    "                              presmooth_temporal=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the original video and motion-compensated video side by side using {func}`optimap.video.play2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "om.video.play2(video,\n",
    "               warped,\n",
    "               title1=\"with motion\",\n",
    "               title2=\"without motion\",\n",
    "               skip_frame=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "render_ani_func(lambda: om.video.play2(video, warped, title1=\"with motion\", title2=\"without motion\", skip_frame=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and rendering videos\n",
    "\n",
    "Let's save the motion-compensated recording as a tiff stack and also render it to a .mp4 video file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "om.video.save_video(warped, 'warped_recording.tiff')\n",
    "om.video.export_video(warped, 'warped_recording.mp4', fps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimap video-player functions such as {func}`optimap.video.play2` can also be exported to a video file:\n",
    "```python\n",
    "animation = om.video.play2(video, warped, title1='Raw', title2='Compensated')\n",
    "animation.save('Example.mp4')\n",
    "```\n",
    "See {meth}`matplotlib.animation.Animation.save` for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fluorescence wave isolation\n",
    "\n",
    "To better visualize the action potential propagation we can compute a pixel-wise normalization to [0, 1] using a sliding/rolling window of 60 frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "norm_raw = om.video.normalize_pixelwise_slidingwindow(video, window_size=60)\n",
    "norm_warped = om.video.normalize_pixelwise_slidingwindow(warped, window_size=60)\n",
    "om.video.play2(norm_raw, norm_warped, title1=\"with motion\", title2=\"without motion\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "def f():\n",
    "    norm_raw = om.video.normalize_pixelwise_slidingwindow(video, window_size=60)\n",
    "    norm_warped = om.video.normalize_pixelwise_slidingwindow(warped, window_size=60)\n",
    "    return om.video.play2(norm_raw[:500], norm_warped[:500], title1=\"with motion\", title2=\"without motion\", interval=20)\n",
    "render_ani_func(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = om.background_mask(warped[0])\n",
    "# norm_warped[:, mask] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "test_name": "notebook1"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
