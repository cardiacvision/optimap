{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Code snippet for rendering animations in the docs\n",
    "from IPython.display import HTML\n",
    "import warnings\n",
    "import matplotlib\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "\n",
    "def render_ani_func(f):\n",
    "    om.utils.disable_interactive_backend_switching()\n",
    "    plt.switch_backend('Agg')\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        ani = f()\n",
    "    %matplotlib inline\n",
    "    om.utils.enable_interactive_backend_switching()\n",
    "\n",
    "    return HTML(ani.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "source": [
    "```{tip}\n",
    "Download this tutorial as a {download}`Jupyter notebook <basics.ipynb>`, or a {download}`python script <basics.py>` with code cells.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Basics\n",
    "\n",
    "This tutorial will walk you through the basics of using the `optimap` package.\n",
    "\n",
    "First, let's import optimap and the other packages we will need:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optimap as om\n",
    "import monochrome as mc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a video file\n",
    "\n",
    "We now have access to all the functions in the `optimap` package. Let's start by loading a video file. We will use the `optimap.video.load` function to load a sample video file.\n",
    "\n",
    "The recording of a beating Rabbit heart stained with the voltage-sensitive dye di-4-ANEPPS was acquired at 500 fps using a Basler acA720-520um camera. The action potentials are inverted, i.e. an upstroke is observed as a negative deflection.\n",
    "\n",
    "We have extracted a short section of the original recording and saved the raw data as a numpy file (`.npy`). See {func}`optimap.video.load` for a list of supported file formats.\n",
    "\n",
    "* experimenter: Jan Lebert, Shrey Chowdhary & Jan Christoph\n",
    "* institution: University of California, San Francisco, USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = om.utils.retrieve_example_data('Example_02_VF_Rabbit_Di-4-ANEPPS_Basler_acA720-520um.npy')\n",
    "video = om.load_video(filepath)\n",
    "\n",
    "om.print_properties(video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimap imports videos as numpy arrays with the shape (Time, Height, Width). This convention is used throughout the library.\n",
    "\n",
    "## Playing videos\n",
    "Videos can be viewed either with the builtin matplotlib viewer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "om.video.play(video);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "render_ani_func(lambda: om.video.play(video))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or with the Monochrome viewer, which is a separate project.\n",
    "\n",
    "In Monochrome click on the video to view time traces at the selected positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "mc.show(video, \"raw video\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing and extracting traces\n",
    "\n",
    "Time traces can be viewed and extracted interactively using the {func}`optimap.trace.select_traces` function. Click on the image to select positions, right click to remove positions. Close the window to continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "traces, positions = om.trace.select_traces(video, size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "positions = [(127, 147), (130, 209), (202, 136)]\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(11,4))\n",
    "om.trace.show_positions(video[0], positions, ax=axs[0])\n",
    "traces = om.trace.extract_traces(video, positions, size=3, ax=axs[1], show=True, fps=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `size` parameter controls the dimensions of the window surrounding the chosen location, from which the average is computed. By default, this window is a rectangle with dimensions `(size, size)`.\n",
    "\n",
    "To get the exact pixel values without averaging, set `size=1`. If you'd like to display the time axis in seconds rather than frames, use the `fps` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = om.extract_traces(video, positions, size=1, show=True, fps=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `window` parameter can be used to define the window function, `'disc'` uses a circular region with radius `size` around the position. See {func}`optimap.trace.select_traces` for more information.\n",
    "\n",
    "Internally {func}`optimap.trace.extract_traces` uses {func}`optimap.trace.show_traces` to plot traces. In general, all plotting functions in optimap have an `ax` parameter which can be used to specify a custom matplotlib axes object.\n",
    "\n",
    "For example, we can create a figure with two subplots and show the positions on the first subplot and the traces on the second subplot with milliseconds as time unit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(10,5))\n",
    "\n",
    "om.trace.show_positions(video[0], positions, ax=axs[0])\n",
    "\n",
    "x_axis_ms = (np.arange(video.shape[0]) / 500.0) * 1000\n",
    "traces = om.extract_traces(video[:300],\n",
    "                           positions,\n",
    "                           x=x_axis_ms[:300],\n",
    "                           size=5,\n",
    "                           window='disc',\n",
    "                           ax=axs[1],\n",
    "                           show=True)\n",
    "axs[1].set_xlabel('Time [ms]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motion Compensation\n",
    "\n",
    "The heart is beating and slightly moving during the recording. Even though the motion is small, it can have a strong effect on the time traces in the form of motion artifacts. We can use the {func}`optimap.motion.motion_compensate` function to compensate for the motion using the steps described in {cite}`Christoph2018a` and {cite}`Lebert2022`. See [](motion_compensation) for detailed information and examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warped = om.motion_compensate(video,\n",
    "                              contrast_kernel=5,\n",
    "                              presmooth_spatial=1,\n",
    "                              presmooth_temporal=1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the original video and motion-compensated video side by side using {func}`optimap.video.play2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "om.video.play2(video,\n",
    "               warped,\n",
    "               title1=\"with motion\",\n",
    "               title2=\"without motion\",\n",
    "               skip_frame=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "render_ani_func(lambda: om.video.play2(video, warped, title1=\"with motion\", title2=\"without motion\", skip_frame=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the motion-compensated recording as a tiff stack and also render it to a .mp4 video file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "om.video.save_video(warped, 'warped_recording.tiff')\n",
    "om.video.export_video(warped, 'warped_recording.mp4', fps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fluorescence wave isolation\n",
    "\n",
    "To better visualize the action potential propagation we can compute a pixel-wise normalization to [0, 1] using a sliding/rolling window of 60 frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "norm_raw = om.video.normalize_pixelwise_slidingwindow(video, window_size=60)\n",
    "norm_warped = om.video.normalize_pixelwise_slidingwindow(warped, window_size=60)\n",
    "om.video.play2(norm_raw, norm_warped, title1=\"with motion\", title2=\"without motion\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "def f():\n",
    "    norm_raw = om.video.normalize_pixelwise_slidingwindow(video, window_size=60)\n",
    "    norm_warped = om.video.normalize_pixelwise_slidingwindow(warped, window_size=60)\n",
    "    return om.video.play2(norm_raw[:500], norm_warped[:500], title1=\"with motion\", title2=\"without motion\", interval=20)\n",
    "render_ani_func(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = om.background_mask(warped[0])\n",
    "# norm_warped[:, mask] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "test_name": "notebook1"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
