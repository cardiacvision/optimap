{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Code snippet for rendering animations in the docs\n",
    "from IPython.display import HTML\n",
    "import warnings\n",
    "import matplotlib\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def render_ani_func(f):\n",
    "    om.utils.disable_interactive_backend_switching()\n",
    "    plt.switch_backend('Agg')\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        ani = f()\n",
    "    %matplotlib inline\n",
    "    om.utils.enable_interactive_backend_switching()\n",
    "\n",
    "    vid = HTML(ani.to_html5_video())\n",
    "    plt.close('all')\n",
    "    return vid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{tip}\n",
    "Download this tutorial as a {download}`Jupyter notebook <converted/motion_compensation.ipynb>`, or a {download}`python script <converted/motion_compensation.py>` with code cells.\n",
    "```\n",
    "\n",
    "# Tutorial 3: Motion Compensation and Ratiometry with Di-4-ANEPPS\n",
    "\n",
    "In this tutorial, we will discuss the analysis of ratiometric optical mapping data showing the ventricular surface of a contracting heart. The heart was stained with Di-4-ANEPPS and imaged using an alternating green and blue illumination at 500fps as described in Kappadan et al. 2020. The tissue was illuminated in every odd frame with green light and in every even frame with blue light, respectively. This approach i sometimess referred to as 'excitation ratiometry'. After numerical motion tracking and stabilization, the green and blue videos are divided by each other to obtain a motion-stabilized ratiometric video. Using this method, both motion artifacts as well as illumination artifacts (which also lead to motion artifacts) can be significantly reduced. \n",
    "\n",
    "First, we load the video data, which is stored as a single file (`Example_05_Ratiometry.npy`) containing the two green and blue videos in an interleaved fashion (frame 1 = green, frame 2 = blue, frame 3 = green, etc.). Using optimap's `load_video()` function, we can specify to load only every 2nd frame and to start reading from the first or the second frame, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optimap as om\n",
    "# import monochrome as mc  # remove this if you don't have monochrome installed\n",
    "\n",
    "#filename = om.utils.retrieve_example_data('Example_01_Sinus_Rabbit_Basler.npy')\n",
    "filename = 'example_data/Example_05_Ratiometry.npy'\n",
    "video_blue = om.load_video(filename, start_frame=0, step=2)\n",
    "video_green = om.load_video(filename, start_frame=1, step=2)\n",
    "\n",
    "\n",
    "video_green = om.video.rotate_left(video_green)\n",
    "video_green = om.video.rotate_left(video_green)\n",
    "\n",
    "video_blue = om.video.rotate_left(video_blue)\n",
    "video_blue = om.video.rotate_left(video_blue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, one could load the video and manually split the video into the green and blue videos (`video_green = video[::2,:,:]` etc.).\n",
    "\n",
    "When we play the two videos next to each other we notice that there is signal in only the green video but not in the blue video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "om.video.play2(video_green, video_blue, title1=\"green video with signal\", title2=\"blue video without signal\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "render_ani_func(lambda: om.video.play2(video_green, 1, title=\"green video with signal\", interval=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-output",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "warped = om.motion.motion_compensate(video_green, 5, ref_frame=40)\n",
    "flows_nocontrast = om.motion.estimate_displacements(video, 40)\n",
    "warped_nocontrast = om.motion.warp_video(video, flows_nocontrast)\n",
    "om.video.playn([video, warped, warped_nocontrast],\n",
    "               titles=[\"original video\", \"with contrast-enhancement\", \"w/o contrast-enhancement\"], figsize=(8, 3.5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "warped_ref0 = om.motion_compensate(video, contrast_kernel=5, ref_frame=0)\n",
    "warped_ref40 = om.motion_compensate(video, contrast_kernel=5, ref_frame=40)\n",
    "om.video.playn([video, warped_ref40, warped_ref0], titles=[\"original video\", \"compensated ref 40\", \"compensated ref 0\"], figsize=(8, 3.5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "warped_ref0 = om.motion_compensate(video, contrast_kernel=5, ref_frame=0)\n",
    "warped_ref40 = om.motion_compensate(video, contrast_kernel=5, ref_frame=40)\n",
    "render_ani_func(lambda: om.video.playn([video, warped_ref40, warped_ref0], titles=[\"original video\", \"compensated ref 40\", \"compensated ref 0\"], interval=20, figsize=(8, 3.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "contrast3 = om.motion.contrast_enhancement(video[:300], 3)\n",
    "contrast5 = om.motion.contrast_enhancement(video[:300], 5)\n",
    "contrast9 = om.motion.contrast_enhancement(video[:300], 9)\n",
    "om.video.playn([contrast3, contrast5, contrast9],\n",
    "               titles=[\"contrast kernel 3\", \"contrast kernel 5\", \"contrast kernel 9\"],\n",
    "               skip_frame=3,\n",
    "               figsize=(8, 3.5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "def f():\n",
    "    contrast3 = om.motion.contrast_enhancement(video[:300], 3)\n",
    "    contrast5 = om.motion.contrast_enhancement(video[:300], 5)\n",
    "    contrast9 = om.motion.contrast_enhancement(video[:300], 9)\n",
    "    return om.video.playn([contrast3, contrast5, contrast9], titles=[\"contrast kernel 3\", \"contrast kernel 5\", \"contrast kernel 9\"], skip_frame=1, figsize=(8, 3.5))\n",
    "render_ani_func(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
